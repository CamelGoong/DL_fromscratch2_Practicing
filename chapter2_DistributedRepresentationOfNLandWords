# 간단한 문장 전처리
text = 'You say goodbye and I say hello.'
text = text.lower() # 모든 문자 소문자로 변환하고, 다시 text로 넣어줘야 함.
text = text.replace(".", " .")
words = text.split(" ")
print(words)

# 단어에 ID 부여하고, 단어ID와 단어의 대응표 작성하기
word_to_id = {} # 딕셔너리 형태
id_to_word = {}

for word in words:
  if word not in word_to_id:
    new_id = len(word_to_id)
    word_to_id[word] = new_id
    id_to_word[new_id] = word

print(id_to_word)
print(word_to_id)

# id로 단어 검색
print(id_to_word[1])

# 단어로 id 검색
print(word_to_id['hello'])

# 단어목록 -> 단어ID목록 -> 넘파이 배열 로 변환.
import numpy as np
corpus = [word_to_id[w] for w in words]
print(corpus)
corpus = np.array(corpus)
print(corpusm)

# 위의 일련의 과정들을 def preprocess 라는 하나의 함수로 귀현
def preprocess(text):
  # 기본 전처리
  text = text.lower()
  text = text.replace(".", " .")
  words = text.split(" ")
  
  # 단어, ID 대응 목록 형성
  word_to_id = {}
  id_to_word = {}
  for word in words:
    if word not in word_to_id:
      new_id = len(word_to_id)
      word_to_id[word] = new_id
      id_to_word[new_id] = word

  # corpus(말뭉치) 형성
  corpus = np.array([word_to_id[w] for w in words])

  return corpus, word_to_id, id_to_word

# def preprocess Test
text = "What I want to do in the future is to do the fabulous things for the society. And I am just a senior university student for now."

preprocess(text)

# 전처리 먼저!
import numpy as np
text = "You say goodbye and I say hello."
corpus, word_to_id, id_to_word = preprocess(text)

print(corpus)
print(id_to_word)

# 동시발생 행렬 표현
import numpy as np
C = np.array([ [0, 1, 0, 0, 0, 0, 0], [1, 0, 1, 0, 1, 1, 0], [0, 1, 0, 1, 0, 0, 0], [0, 0, 1, 0, 1, 0, 0], [0, 1, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0]], dtype = np.int32)
print(C)

# id가 2인 'goodbye'의 벡터 표현
print(C[word_to_id['goodbye']])

import numpy as np
# create_co_matrix 함수 구현
def create_co_matrix(corpus, vocab_size, window_size=1):
    corpus_size = len(corpus)
    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)

    for idx, word_id in enumerate(corpus):
        for i in range(1, window_size + 1):
            left_idx = idx - i
            right_idx = idx + i

            if left_idx >= 0:
                left_word_id = corpus[left_idx]
                co_matrix[word_id, left_word_id] += 1

            if right_idx < corpus_size:
                right_word_id = corpus[right_idx]
                co_matrix[word_id, right_word_id] += 1

    return co_matrix
# 코사인 유사도 구현
def cos_similarity(x, y, eps = 1e-8):
  nx = x / (np.sqrt(np.sum(x**2)) + eps) # x의 정규화
  ny = y / (np.sqrt(np.sum(y**2)) + eps) # y의 정규화
  return np.dot(nx, ny)
  
  # 'you'와 i의 유사도 구하기
text = 'You say goodbye and I say hello.'
corpus, word_to_id, id_to_word, = preprocess(text)
vocab_size = len(word_to_id)
C = create_co_matrix(corpus, vocab_size = vocab_size)

c0 = C[word_to_id['you']] # you의 벡터
c1 = C[word_to_id['i']] # i의 벡터
print(cos_similarity(c0, c1))

def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):
    '''유사 단어 검색

    :param query: 쿼리(텍스트)
    :param word_to_id: 단어에서 단어 ID로 변환하는 딕셔너리
    :param id_to_word: 단어 ID에서 단어로 변환하는 딕셔너리
    :param word_matrix: 단어 벡터를 정리한 행렬. 각 행에 해당 단어 벡터가 저장되어 있다고 가정한다.
    :param top: 상위 몇 개까지 출력할 지 지정
    '''
    if query not in word_to_id:
        print('%s(을)를 찾을 수 없습니다.' % query)
        return

    print('\n[query] ' + query)
    query_id = word_to_id[query]
    query_vec = word_matrix[query_id]

    # 코사인 유사도 계산
    vocab_size = len(id_to_word)

    similarity = np.zeros(vocab_size)
    for i in range(vocab_size):
        similarity[i] = cos_similarity(word_matrix[i], query_vec)

    # 코사인 유사도를 기준으로 내림차순으로 출력
    count = 0
    for i in (-1 * similarity).argsort():
        if id_to_word[i] == query:
            continue
        print(' %s: %s' % (id_to_word[i], similarity[i]))

        count += 1
        if count >= top:
            return

# coding: utf-8
text = 'You say goodbye and I say hello.'
corpus, word_to_id, id_to_word = preprocess(text)
vocab_size = len(word_to_id)
C = create_co_matrix(corpus, vocab_size)
W = ppmi(C)

np.set_printoptions(precision=3)  # 유효 자릿수를 세 자리로 표시
print('동시발생 행렬')
print(C)
print('-'*50)
print('PPMI')
print(W)

import numpy as np
import matplotlib.pyplot as plt

text = 'You say goodbye and I say hello.'
corpus, word_to_id, id_to_word = preprocess(text)
vocab_size = len(id_to_word)
C = create_co_matrix(corpus, vocab_size, window_size = 1)
W = ppmi(C)

# SVD 구현
U, S, V = np.linalg.svd(W)
print(U[0])
print(U[0,:2])

for word, word_id in word_to_id.items():
  plt.annotate(word, (U[word_id, 0], U[word_id, 1]))

plt.scatter(U[:, 0], U[:, 1], alpha = 0.5)
plt.show()

from google.colab import drive
drive.mount('/content/drive')

import sys
sys.path.append('/content/drive/My Drive')
print(sys.path)
import ptb

corpus, word_to_id, id_to_word = ptb.load_data('train')

print('말뭉치 크기: ', len(corpus))
print('corpus[:30]: ', corpus[:30])
print()
print('id_to_word[0]: ', id_to_word[0])
print('id_to_word[1]: ', id_to_word[1])
print('id_to_word[2]: ', id_to_word[2])
print()
print("word_to_id['car']: ", word_to_id['car'])
print("word_to_id['happy']: ", word_to_id['happy'])
print("word_to_id['lexus']: ", word_to_id['lexus'])

import numpy as np
window_size = 2
wordvec_size = 100

corpus, word_id, id_to_word = ptb.load_data('train')
vocab_size = len(word_to_id)
print('동시발생 수 계산 ...')
C = create_co_matrix(corpus, vocab_size, window_size)
print('PPMI 계산 ...')
W = ppmi(C, verbose = True)

print('SVD 계산 ...')
try:
  # truncated SVD 사용 from sklearn (개빠름)
  from sklearn.utils.extmath import randomized_svd
  U, S, V = randomized_svd(W, n_components = wordvec_size, n_iter = 5,
                           random_state = None)
except ImportError:
  #SVD (느리다!)
  U, S, V = np.linalg.svd(W)

word_vecs = U[:, :wordvec_size]
querys = ['you', 'year', 'car', 'toyota']

# 쿼리를 리스트에서 하나씩 불러옴.
for query in querys:
  most_similar(query, word_to_id, id_to_word, word_vecs, top = 5)
